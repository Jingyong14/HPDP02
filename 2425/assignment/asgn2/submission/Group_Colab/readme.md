## ðŸ‘¥ Group Members

- Wong Qiao Ying (A22EC0118)
- Nik Zulaikhaa Binti Zuraidi Afandi (A22EC0232)

---
## Introduction
In the modern data-driven world, organizations face the challenge of managing and extracting insights from massive datasets that far exceed the capabilities of traditional data handling tools. This assignment provides hands-on experience in managing such datasets using Python and its scalable libraries.

In this assignment, a dataset with 1GB size will be used to performed a few optimized strategies including:
- Load Less Data
- Use Chunking
- Optimize Data Types
- Sampling
- Parallel Processing with Dask

## ðŸ“‚ Project Resources

- ðŸ“Š **Dataset**: [900K Spotify Dataset on Kaggle](https://www.kaggle.com/datasets/devdope/900k-spotify)
- ðŸ’» **Google Colab Notebook**: [Colab Link](https://colab.research.google.com/drive/195WtU92RuX6so3w6lBtXNdQntwDj_rmk?usp=sharing)
- ðŸ“˜ **Assignment Logbook**: [Google Docs Logbook](https://docs.google.com/document/d/1kHPzdrlHnGcFiWhbS9kZ4wsZAI8TMlyzq94FyRQA110/edit?usp=sharing)

