# SECP3133 High Performance Data Processing - Section 02

## Assignment 2 - Mastering Big Data Handling

### Group Shockwave:
- **LIM JING YONG** - A22EC0182  
- **LEE SOON DER** - A22EC0065

---

## Task 1: Dataset Selection

In this section, we decided to select our dataset in Kaggle due to its functionality to show the size of the dataset (in MB). This allows us to quickly find suitable and large enough dataset to undergo optimization during the dataset loading process.

The dataset we chose is the **continental2.csv** file from the _COVID-19 in the American Continent_ dataset, which consists of **1.07 GB** of data. This dataset records the number of COVID-19 cases that happened across the years 2020 to 2022 in different countries.

![Kaggle CSV View](figures/kaggle_screenshot.png)  
**Figure 1.1**: View of the CSV file in Kaggle

The dataset consists of **14 columns** (2 irrelevant ID columns) and **1,048,576 rows** of data.

![CSV Screenshot Part 1](figures/csv_screenshot1.png)  
![CSV Screenshot Part 2](figures/csv_screenshot2.png)  
**Figure 1.2**: Data columns and row count from the CSV file

