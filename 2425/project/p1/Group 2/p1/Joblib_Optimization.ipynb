{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# High Performance Data Cleaning - JobLib\n",
        "\n",
        "!pip install joblib\n",
        "\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "# Performance tracking start\n",
        "start_time = time.time()\n",
        "process = psutil.Process(os.getpid())\n",
        "cpu_start = psutil.cpu_percent(interval=None)\n",
        "mem_before = process.memory_info().rss / (1024 * 1024)  # in MB"
      ],
      "metadata": {
        "id": "0QlPhZTNXn69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "raw_df = pl.read_csv(\"new_iproperty_dataset.csv\")\n",
        "\n",
        "raw_pd_df = raw_df.to_pandas()\n",
        "\n",
        "conn = sqlite3.connect(\"iproperty.db\")\n",
        "\n",
        "raw_pd_df.to_sql(\"raw_data\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# Now you can safely read\n",
        "df = pd.read_sql_query(\"SELECT * FROM raw_data\", conn)\n"
      ],
      "metadata": {
        "id": "dpAhkKexVmfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Start tracking performance\n",
        "start_time = time.time()\n",
        "process = psutil.Process(os.getpid())\n",
        "mem_before = process.memory_info().rss / (1024 * 1024)\n",
        "\n",
        "# Read and convert\n",
        "raw_df = pl.read_csv(\"new_iproperty_dataset.csv\")\n",
        "raw_pd_df = raw_df.to_pandas()\n",
        "\n",
        "# Save to SQLite\n",
        "conn = sqlite3.connect(\"iproperty.db\")\n",
        "raw_pd_df.to_sql(\"raw_data\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# Read into Pandas\n",
        "df = pd.read_sql_query(\"SELECT * FROM raw_data\", conn)\n",
        "\n",
        "# Rename Area to Area Code\n",
        "df.rename(columns={'Area': 'Area Code'}, inplace=True)\n",
        "\n",
        "# Clean Property Title\n",
        "df['Property Title'] = df['Property Title'].str.split(',').str[0].str.title()\n",
        "\n",
        "# Clean Property Price\n",
        "df['Property Price'] = (\n",
        "    df['Property Price']\n",
        "    .str.replace('RM', '', regex=False)\n",
        "    .str.replace(',', '', regex=False)\n",
        ")\n",
        "df['Property Price'] = pd.to_numeric(df['Property Price'], errors='coerce')\n",
        "df.rename(columns={'Property Price': 'Property Price (RM)'}, inplace=True)\n",
        "\n",
        "# Clean Property Location\n",
        "split_cols = df['Property Location'].str.split(', ', expand=True)\n",
        "df.drop(columns=['Property Location'], inplace=True)\n",
        "df.insert(2, 'Property Location (City)', split_cols[0])\n",
        "df.insert(3, 'Property Location (State)', split_cols[1])\n",
        "\n",
        "# Define parsing function\n",
        "def parse_property_details(detail):\n",
        "    if pd.isnull(detail):\n",
        "        return [None, None, None]\n",
        "    clean_detail = re.sub(r'[^\\x00-\\x7F]+', ' ', str(detail))\n",
        "    type_match = re.search(r\"^(.*?)Built-up\", clean_detail, re.IGNORECASE)\n",
        "    property_type = re.split(r'\\s*\\|\\s*', type_match.group(1).strip())[0] if type_match else None\n",
        "    area_match = re.search(r'Built[-\\s]*up[^0-9]*([\\d,]+)\\s*sq\\.?\\s*ft', clean_detail, re.IGNORECASE)\n",
        "    area = float(area_match.group(1).replace(',', '')) if area_match else None\n",
        "    furnishing = \"Unknown\"\n",
        "    if re.search(r'\\bUnfurnished\\b', clean_detail, re.IGNORECASE):\n",
        "        furnishing = 'Unfurnished'\n",
        "    elif re.search(r'\\bPartially Furnished\\b', clean_detail, re.IGNORECASE):\n",
        "        furnishing = 'Partially Furnished'\n",
        "    elif re.search(r'\\bFully Furnished\\b', clean_detail, re.IGNORECASE):\n",
        "        furnishing = 'Fully Furnished'\n",
        "    elif re.search(r'\\bFurnished\\b', clean_detail, re.IGNORECASE):\n",
        "        furnishing = 'Furnished'\n",
        "    return [property_type, area, furnishing]\n",
        "\n",
        "# Parallel cleaning\n",
        "results = Parallel(n_jobs=-1)(delayed(parse_property_details)(d) for d in df['Property Details'])\n",
        "df[['Property Type', 'Property Size (sqft)', 'Property Furnishing Status']] = pd.DataFrame(results)\n",
        "\n",
        "# Drop original column\n",
        "df.drop(columns=['Property Details'], inplace=True)\n",
        "\n",
        "# Clean Agent\n",
        "df['Property Agent'] = df['Property Agent'].str.title()\n",
        "df['Property Agent'] = df['Property Agent'].apply(\n",
        "    lambda x: None if re.search(r'\\bsdn\\.?\\s*bhd\\.?\\b', str(x), re.IGNORECASE) else x\n",
        ")\n",
        "\n",
        "# Final cleaning steps\n",
        "df.dropna(subset=['Property Price (RM)'], inplace=True)\n",
        "df.dropna(subset=['Property Type'], inplace=True)\n",
        "df = df[df['Property Size (sqft)'] >= 70]\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Save cleaned data\n",
        "df.to_sql(\"cleaned_data\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# End tracking\n",
        "end_time = time.time()\n",
        "mem_after = process.memory_info().rss / (1024 * 1024)\n",
        "total_runtime = end_time - start_time\n",
        "mem_used = mem_after - mem_before\n",
        "total_records = df.shape[0]\n",
        "throughput = total_records / total_runtime if total_runtime > 0 else 0\n",
        "\n",
        "# Fancy output\n",
        "print(\"📊 Performance Summary\")\n",
        "print(f\"📦 Total Records Processed: {total_records}\")\n",
        "print(f\"⏱️ Total Processing Time: {total_runtime:.2f} seconds\")\n",
        "print(f\"🛠️ Memory Used (Before ➜ After): {mem_before:.2f} MB ➜ {mem_after:.2f} MB\")\n",
        "print(f\"🔺 Peak Memory Usage: {mem_used:.2f} MB\")\n",
        "print(f\"📈 Throughput: {throughput:.2f} records/second\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIdDPG4Gc0jl",
        "outputId": "66c9a1c9-f488-4a7f-a43b-9f0d482b9617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Performance Summary\n",
            "📦 Total Records Processed: 144214\n",
            "⏱️ Total Processing Time: 20.19 seconds\n",
            "🛠️ Memory Used (Before ➜ After): 182.28 MB ➜ 567.96 MB\n",
            "🔺 Peak Memory Usage: 385.68 MB\n",
            "📈 Throughput: 7141.52 records/second\n"
          ]
        }
      ]
    }
  ]
}