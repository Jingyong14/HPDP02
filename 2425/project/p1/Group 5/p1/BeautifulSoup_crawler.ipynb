{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Range of pet IDs\n",
    "start_id = 2001\n",
    "end_id = 36500  # inclusive\n",
    "\n",
    "# Async function to scrape one pet\n",
    "async def scrape_pet(session, pet_id):\n",
    "    url = f\"https://www.petfinder.my/pets/{pet_id}/\"\n",
    "    try:\n",
    "        await asyncio.sleep(30)  # Respect robots.txt: 30-second delay between requests\n",
    "        async with session.get(url) as response:\n",
    "            html = await response.text()\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "            # Extract pet name\n",
    "            pet_title_tag = soup.find('div', class_='pet_title')\n",
    "            pet_name = pet_title_tag.find('td', align=\"center\").text.strip() if pet_title_tag else \"N/A\"\n",
    "\n",
    "            # Extract details\n",
    "            info_table = soup.find('table', class_='pet_box')\n",
    "            pet_details = {}\n",
    "\n",
    "            if info_table:\n",
    "                rows = info_table.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    if len(cols) >= 2:\n",
    "                        key_tag = cols[0].find('b')\n",
    "                        if key_tag:\n",
    "                            key = key_tag.text.strip().replace(\":\", \"\")\n",
    "                            value = cols[1].text.strip()\n",
    "                            pet_details[key] = value\n",
    "\n",
    "            # Type and Species\n",
    "            pet_type = next(iter(pet_details.keys()), \"N/A\")\n",
    "            pet_species = pet_details.get(pet_type, \"N/A\")\n",
    "\n",
    "            # Price/Adoption Fee\n",
    "            adoption_fee = \"N/A\"\n",
    "            if info_table:\n",
    "                rows = info_table.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    if len(cols) >= 2:\n",
    "                        key_tag = cols[0].find('b')\n",
    "                        if key_tag and 'Adoption Fee' in key_tag.text:\n",
    "                            fee_tag = cols[1].find('b')\n",
    "                            if fee_tag:\n",
    "                                adoption_fee = fee_tag.text.strip()\n",
    "                            else:\n",
    "                                adoption_fee = cols[1].text.strip()\n",
    "\n",
    "            # Uploader Type and Name\n",
    "            uploader_td = soup.find('td', align=\"left\", width=\"130\", valign=\"middle\")\n",
    "            uploader_type = \"N/A\"\n",
    "            uploader_name = \"N/A\"\n",
    "\n",
    "            if uploader_td:\n",
    "                font_tag = uploader_td.find('font')\n",
    "                uploader_type = font_tag.text.strip() if font_tag else \"N/A\"\n",
    "                uploader_name_tag = uploader_td.find('a', class_='darkgrey')\n",
    "                uploader_name = uploader_name_tag.text.strip() if uploader_name_tag else \"N/A\"\n",
    "\n",
    "            # Status\n",
    "            status_tag = soup.find('div', class_='pet_label')\n",
    "            pet_status = status_tag.text.strip() if status_tag else \"N/A\"\n",
    "\n",
    "            # Save data to CSV progressively\n",
    "            with open('pets_2001_36500.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([\n",
    "                    pet_id,\n",
    "                    pet_name,\n",
    "                    pet_type,\n",
    "                    pet_species,\n",
    "                    pet_details.get('Profile', 'N/A'),\n",
    "                    pet_details.get('Amount', 'N/A'),\n",
    "                    pet_details.get('Vaccinated', 'N/A'),\n",
    "                    pet_details.get('Dewormed', 'N/A'),\n",
    "                    pet_details.get('Spayed', 'N/A'),\n",
    "                    pet_details.get('Condition', 'N/A'),\n",
    "                    pet_details.get('Body', 'N/A'),\n",
    "                    pet_details.get('Color', 'N/A'),\n",
    "                    pet_details.get('Location', 'N/A'),\n",
    "                    pet_details.get('Posted', 'N/A'),\n",
    "                    adoption_fee,\n",
    "                    uploader_type,\n",
    "                    uploader_name,\n",
    "                    pet_status\n",
    "                ])\n",
    "                csvfile.flush()  # Force write to disk immediately\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape pet {pet_id}: {e}\")\n",
    "\n",
    "# Main async runner\n",
    "async def main():\n",
    "    # Write CSV header once before scraping\n",
    "    with open('pets_2001_36500.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow([\n",
    "            \"Pet ID\", \"Name\", \"Type\", \"Species\", \"Profile\", \"Amount\", \"Vaccinated\", \"Dewormed\",\n",
    "            \"Spayed\", \"Condition\", \"Body\", \"Color\", \"Location\", \"Posted\", \"Price\",\n",
    "            \"Uploader Type\", \"Uploader Name\", \"Status\"\n",
    "        ])\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for pet_id in range(start_id, end_id + 1):\n",
    "            await scrape_pet(session, pet_id)  # Sequential with delay\n",
    "\n",
    "# Run the async function\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
